{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data set\n",
    "import pandas as pd\n",
    "train=pd.read_csv('Tweets-train.csv')\n",
    "\n",
    "#Selecting only sentiment and tweet column from the entire data set\n",
    "train=train[['airline_sentiment','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@USAirways it was customer service like I have never seen before!  Kudos to your organization.\n",
      "@AmericanAir I love your company and your staff is amazing. They just made an uncomfortable situation comfortable\n",
      "@united I appreciate the follow up.\n",
      "@JetBlue boarding the back of the airplane first. Like a boss. #sosmart #jetblue #frequentflyerappreciates #alsoyayforsnacks\n",
      "@AmericanAir mission accomplished today, Thank you!\n",
      "@united thnx\n",
      "@united thank you for following up!\n",
      "@JetBlue thanks so much!! ‚ù§Ô∏è‚ú® very relaxing flight!\n",
      "@USAirways thanks for seating me next to 2 hot athletes. This flight is significantly better now!\n",
      "@united awesome new plane flight 1701\n"
     ]
    }
   ],
   "source": [
    "#See some positive sentiments\n",
    "for each in train[train['airline_sentiment']==\"positive\"].sample(10,random_state=10)['text']:\n",
    "    print (each) \n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@AmericanAir continues to win: I've never missed a flight before, but a nice little quiet gate change made it possible. Sheesh.\n",
      "@united is that all that matters, not the fact that we're at a different destination, we were put through a tremendous amount of stress,\n",
      "@USAirways your lack of customer service has shined. I need you to step up and get my lost baggage to delta. So they can return it to me.\n",
      "@united Terribly disappointed. Confirmed reservation delayed and your cust. service staff was not helpful in finding an alternate solution.\n",
      "@united what is this subtlety gate changes? Are you kidding with me?\n",
      "@SouthwestAir and now no wifi??? Come on.\n",
      "@JetBlue is flight 51 on 4/24/15 moved back? When I booked it said we arrive 11:31 but now it says 12:08 üò¢\n",
      "@AmericanAir complt incompetence on flt 295.Lav delay from a pln that lnded last nite, no internet and poor svc. Not what I expect from u.\n",
      "@united @annricord 0162431184663.\n",
      "3 of your agents said we would be refunded. Agents said United should never have sold us the ticket.\n",
      "@united I'm checked in, agent wouldn't tag my bags at 7am. Now I'm standing in line hell.\n"
     ]
    }
   ],
   "source": [
    "#See some negative sentiments\n",
    "for each in train[train['airline_sentiment']==\"negative\"].sample(10,random_state=10)['text']:\n",
    "    print (each )\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@JetBlue you guys get rid of the hip hop stations on Sirius XM?\n",
      "@JetBlue deal!\n",
      "@united can I request a ticket change through twitter ?\n",
      "@united My mom left her Kindle on flight 1544 today. Burgundy case with a light. Seat 27D. Did anyone find it?\n",
      "@USAirways am 2. 1/2 hours from airport sure would like to talk to someone\n",
      "@JetBlue well I'm not sure I'm that bold! lol or are you saying you didn't believe me?? :P\n",
      "@united can you send me another confirmation email?\n",
      "@SouthwestAir first time flyer, scheduled a (round)trip. set on departure date not sure on returning date, policy/fees on changing Re Flight\n",
      "@SouthwestAir still haven't been able to get through, thanks for responding\n",
      "@USAirways we even offered to fly in to another airport and they said they couldn't do that. No explanation why they can't.\n"
     ]
    }
   ],
   "source": [
    "#See some neutral sentiments\n",
    "for each in train[train['airline_sentiment']==\"neutral\"].sample(10,random_state=10)['text']:\n",
    "    print (each )\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D\n",
      "virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D\n"
     ]
    }
   ],
   "source": [
    "#@ mentions\n",
    "import re\n",
    "\n",
    "print (train.text[5])\n",
    "print \n",
    "print (re.sub(r'@+','',train.text[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica @virginmedia I'm flying your #fabulous #Seductive skies again! U take all the #stress away from travel http://t.co/ahlXHhKiyn\n",
      "@VirginAmerica @virginmedia I'm flying your #fabulous #Seductive skies again! U take all the #stress away from travel \n"
     ]
    }
   ],
   "source": [
    "#Links \n",
    "\n",
    "print (train.text[10])\n",
    "print \n",
    "print (re.sub('http?://[A-Za-z0-9./]+','',train.text[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica amazing to me that we can't get any cold air from the vents. #VX358 #noair #worstflightever #roasted #SFOtoBOS\n",
      " VirginAmerica amazing to me that we can t get any cold air from the vents   VX358  noair  worstflightever  roasted  SFOtoBOS\n",
      "@JetBlue thanks so much!! ‚ù§Ô∏è‚ú® very relaxing flight!\n",
      " JetBlue thanks so much       very relaxing flight \n"
     ]
    }
   ],
   "source": [
    "# selects only aplhabets numbers so that punctuations and emoticons are removed.\n",
    "\n",
    "print (train.text[22])\n",
    "print \n",
    "print (re.sub(\"[^a-zA-Z0-9]\", \" \",train.text[22]))\n",
    "print \n",
    "print \n",
    "print (train.text[5977])\n",
    "print \n",
    "print (re.sub(\"[^a-zA-Z0-9]\", \" \",train.text[5977]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "def tweet_cleaner(text):\n",
    "    text=re.sub(r'@+','',text)\n",
    "    text=re.sub('http?://[A-Za-z0-9./]+','',text)\n",
    "    text=re.sub(\"[^a-zA-Z]\", \" \",text)\n",
    "    lower_case = text.lower()\n",
    "    words = tokenizer.tokenize(lower_case)\n",
    "    return (\" \".join(words).strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>Cleaned-Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>virginamerica plus you ve added commercials to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>virginamerica i didn t today must mean i need ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>virginamerica it s really aggressive to blast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>virginamerica and it s a really big bad thing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0          positive  @VirginAmerica plus you've added commercials t...   \n",
       "1           neutral  @VirginAmerica I didn't today... Must mean I n...   \n",
       "2          negative  @VirginAmerica it's really aggressive to blast...   \n",
       "3          negative  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "                                        Cleaned-Text  \n",
       "0  virginamerica plus you ve added commercials to...  \n",
       "1  virginamerica i didn t today must mean i need ...  \n",
       "2  virginamerica it s really aggressive to blast ...  \n",
       "3  virginamerica and it s a really big bad thing ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Cleaned-Text']= [tweet_cleaner(x) for x in train['text']]\n",
    "train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "[('to', 4326), ('i', 3313), ('the', 3021), ('a', 2344), ('flight', 2113), ('united', 2101), ('and', 2049), ('on', 2023), ('for', 1999), ('you', 1959), ('my', 1726), ('usairways', 1722), ('americanair', 1549), ('is', 1526), ('t', 1327)]\n",
      "neutral\n",
      "[('to', 1185), ('i', 1004), ('the', 730), ('a', 616), ('you', 561), ('jetblue', 540), ('united', 530), ('southwestair', 489), ('on', 479), ('for', 443), ('flight', 436), ('my', 391), ('is', 372), ('americanair', 363), ('in', 355)]\n",
      "positive\n",
      "[('the', 690), ('to', 675), ('you', 672), ('i', 555), ('for', 493), ('thanks', 448), ('jetblue', 443), ('southwestair', 424), ('a', 385), ('united', 376), ('thank', 336), ('and', 306), ('flight', 269), ('my', 263), ('americanair', 254)]\n"
     ]
    }
   ],
   "source": [
    "#See some words in All sentiments\n",
    "\n",
    "from collections import Counter\n",
    "for group_name,subset in train.groupby('airline_sentiment'):\n",
    "    sentimentData=subset['Cleaned-Text']\n",
    "    words=[]\n",
    "    for each in sentimentData:\n",
    "        words.extend(each.split(\" \"))\n",
    "    print (group_name)\n",
    "    print (Counter(words).most_common(15))\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import regexp_tokenize, blankline_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.util import bigrams, trigrams, ngrams\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Raghu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Raghu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import regexp_tokenize, blankline_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "def RemoveStopWords(gold):\n",
    "    \n",
    "    gold_word_tokenize = word_tokenize(gold)\n",
    "    #print(gold_word_tokenize)\n",
    "    punctuation=re.compile(r'[-.?!,:;%()|0-9]')\n",
    "    post_punctuation=[]\n",
    "    for words in gold_word_tokenize:\n",
    "        word=punctuation.sub(\"\",words)\n",
    "        if len(word)>0:\n",
    "            post_punctuation.append(word)\n",
    "    post_stop_words=[]\n",
    "    stp_words=stopwords.words('english')\n",
    "    for words in post_punctuation:\n",
    "        words=words.lower()\n",
    "        if words not in stp_words:\n",
    "            post_stop_words.append(words)\n",
    "    #print(post_stop_words)        \n",
    "    return (post_stop_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Clean-Text-StopWords-Removed']= [RemoveStopWords(x) for x in train['Cleaned-Text']]\n",
    "#train['Clean-Text-StopWords-Removed']=map(lambda x:RemoveStopWords(x),train['Cleaned-Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>Cleaned-Text</th>\n",
       "      <th>Clean-Text-StopWords-Removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>virginamerica plus you ve added commercials to...</td>\n",
       "      <td>[virginamerica, plus, added, commercials, expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>virginamerica i didn t today must mean i need ...</td>\n",
       "      <td>[virginamerica, today, must, mean, need, take,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>virginamerica it s really aggressive to blast ...</td>\n",
       "      <td>[virginamerica, really, aggressive, blast, obn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>virginamerica and it s a really big bad thing ...</td>\n",
       "      <td>[virginamerica, really, big, bad, thing]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0          positive  @VirginAmerica plus you've added commercials t...   \n",
       "1           neutral  @VirginAmerica I didn't today... Must mean I n...   \n",
       "2          negative  @VirginAmerica it's really aggressive to blast...   \n",
       "3          negative  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "                                        Cleaned-Text  \\\n",
       "0  virginamerica plus you ve added commercials to...   \n",
       "1  virginamerica i didn t today must mean i need ...   \n",
       "2  virginamerica it s really aggressive to blast ...   \n",
       "3  virginamerica and it s a really big bad thing ...   \n",
       "\n",
       "                        Clean-Text-StopWords-Removed  \n",
       "0  [virginamerica, plus, added, commercials, expe...  \n",
       "1  [virginamerica, today, must, mean, need, take,...  \n",
       "2  [virginamerica, really, aggressive, blast, obn...  \n",
       "3           [virginamerica, really, big, bad, thing]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "[('flight', 2113), ('united', 2101), ('usairways', 1722), ('americanair', 1549), ('southwestair', 884), ('jetblue', 755), ('get', 728), ('cancelled', 648), ('service', 530), ('hours', 502), ('help', 443), ('customer', 428), ('time', 426), ('hold', 424), ('plane', 387)]\n",
      "neutral\n",
      "[('jetblue', 540), ('united', 530), ('southwestair', 489), ('flight', 436), ('americanair', 363), ('usairways', 302), ('get', 173), ('please', 132), ('virginamerica', 130), ('flights', 130), ('help', 121), ('thanks', 115), ('need', 114), ('would', 92), ('dm', 91)]\n",
      "positive\n",
      "[('thanks', 448), ('jetblue', 443), ('southwestair', 424), ('united', 376), ('thank', 336), ('flight', 269), ('americanair', 254), ('usairways', 199), ('great', 165), ('service', 120), ('virginamerica', 114), ('love', 105), ('best', 85), ('customer', 85), ('good', 82)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "for group_name,subset in train.groupby('airline_sentiment'):\n",
    "    sentimentData=subset['Clean-Text-StopWords-Removed']\n",
    "    words=[]\n",
    "    for each in sentimentData:\n",
    "        words.extend(each)\n",
    "    print (group_name)\n",
    "    print (Counter(words).most_common(15))\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_words_to_remove=['americanair','united','delta','southwestair','jetblue','virginamerica','usairways','flight','plane']\n",
    "def RemoveExplicitlyMentionedWords(string,listofWordsToRemove):\n",
    "    listOfAllWords=string\n",
    "    listOfWords= [x for x in listOfAllWords if x not in listofWordsToRemove]\n",
    "    return (\" \".join(listOfWords)).strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train['Final-Wrangled-Text']=map(lambda x:RemoveExplicitlyMentionedWords(x,list_of_words_to_remove),train['Clean-Text-StopWords-Removed'])\n",
    "train['Final-Wrangled-Text']= [RemoveExplicitlyMentionedWords(x,list_of_words_to_remove) for x in train['Clean-Text-StopWords-Removed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>Cleaned-Text</th>\n",
       "      <th>Clean-Text-StopWords-Removed</th>\n",
       "      <th>Final-Wrangled-Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>virginamerica plus you ve added commercials to...</td>\n",
       "      <td>[virginamerica, plus, added, commercials, expe...</td>\n",
       "      <td>plus added commercials experience tacky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>virginamerica i didn t today must mean i need ...</td>\n",
       "      <td>[virginamerica, today, must, mean, need, take,...</td>\n",
       "      <td>today must mean need take another trip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>virginamerica it s really aggressive to blast ...</td>\n",
       "      <td>[virginamerica, really, aggressive, blast, obn...</td>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>virginamerica and it s a really big bad thing ...</td>\n",
       "      <td>[virginamerica, really, big, bad, thing]</td>\n",
       "      <td>really big bad thing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0          positive  @VirginAmerica plus you've added commercials t...   \n",
       "1           neutral  @VirginAmerica I didn't today... Must mean I n...   \n",
       "2          negative  @VirginAmerica it's really aggressive to blast...   \n",
       "3          negative  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "                                        Cleaned-Text  \\\n",
       "0  virginamerica plus you ve added commercials to...   \n",
       "1  virginamerica i didn t today must mean i need ...   \n",
       "2  virginamerica it s really aggressive to blast ...   \n",
       "3  virginamerica and it s a really big bad thing ...   \n",
       "\n",
       "                        Clean-Text-StopWords-Removed  \\\n",
       "0  [virginamerica, plus, added, commercials, expe...   \n",
       "1  [virginamerica, today, must, mean, need, take,...   \n",
       "2  [virginamerica, really, aggressive, blast, obn...   \n",
       "3           [virginamerica, really, big, bad, thing]   \n",
       "\n",
       "                                 Final-Wrangled-Text  \n",
       "0            plus added commercials experience tacky  \n",
       "1             today must mean need take another trip  \n",
       "2  really aggressive blast obnoxious entertainmen...  \n",
       "3                               really big bad thing  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "[('get', 728), ('cancelled', 648), ('service', 530), ('hours', 502), ('help', 443), ('customer', 428), ('time', 426), ('hold', 424), ('delayed', 371), ('amp', 368), ('us', 364), ('still', 363), ('call', 334), ('hour', 324), ('one', 322)]\n",
      "neutral\n",
      "[('get', 173), ('please', 132), ('flights', 130), ('help', 121), ('thanks', 115), ('need', 114), ('would', 92), ('dm', 91), ('time', 80), ('tomorrow', 76), ('cancelled', 74), ('amp', 73), ('know', 72), ('us', 72), ('fleek', 70)]\n",
      "positive\n",
      "[('thanks', 448), ('thank', 336), ('great', 165), ('service', 120), ('love', 105), ('best', 85), ('customer', 85), ('good', 82), ('guys', 81), ('much', 77), ('get', 76), ('got', 72), ('awesome', 71), ('help', 65), ('time', 64)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "for group_name,subset in train.groupby('airline_sentiment'):\n",
    "    sentimentData=subset['Final-Wrangled-Text']\n",
    "    words=[]\n",
    "    for each in sentimentData:\n",
    "        words.extend(each.split(\" \"))\n",
    "    print (group_name)\n",
    "    print (Counter(words).most_common(15))\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>Cleaned-Text</th>\n",
       "      <th>Clean-Text-StopWords-Removed</th>\n",
       "      <th>Final-Wrangled-Text</th>\n",
       "      <th>SentimentLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>virginamerica plus you ve added commercials to...</td>\n",
       "      <td>[virginamerica, plus, added, commercials, expe...</td>\n",
       "      <td>plus added commercials experience tacky</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>virginamerica i didn t today must mean i need ...</td>\n",
       "      <td>[virginamerica, today, must, mean, need, take,...</td>\n",
       "      <td>today must mean need take another trip</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>virginamerica it s really aggressive to blast ...</td>\n",
       "      <td>[virginamerica, really, aggressive, blast, obn...</td>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>virginamerica and it s a really big bad thing ...</td>\n",
       "      <td>[virginamerica, really, big, bad, thing]</td>\n",
       "      <td>really big bad thing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0          positive  @VirginAmerica plus you've added commercials t...   \n",
       "1           neutral  @VirginAmerica I didn't today... Must mean I n...   \n",
       "2          negative  @VirginAmerica it's really aggressive to blast...   \n",
       "3          negative  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "                                        Cleaned-Text  \\\n",
       "0  virginamerica plus you ve added commercials to...   \n",
       "1  virginamerica i didn t today must mean i need ...   \n",
       "2  virginamerica it s really aggressive to blast ...   \n",
       "3  virginamerica and it s a really big bad thing ...   \n",
       "\n",
       "                        Clean-Text-StopWords-Removed  \\\n",
       "0  [virginamerica, plus, added, commercials, expe...   \n",
       "1  [virginamerica, today, must, mean, need, take,...   \n",
       "2  [virginamerica, really, aggressive, blast, obn...   \n",
       "3           [virginamerica, really, big, bad, thing]   \n",
       "\n",
       "                                 Final-Wrangled-Text  SentimentLabel  \n",
       "0            plus added commercials experience tacky               2  \n",
       "1             today must mean need take another trip               1  \n",
       "2  really aggressive blast obnoxious entertainmen...               0  \n",
       "3                               really big bad thing               0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "l=LabelEncoder()\n",
    "train['SentimentLabel']=l.fit_transform(train['airline_sentiment'])\n",
    "train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train['SentimentLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=vectorizer.fit_transform(train['Final-Wrangled-Text'])\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('Tweets-test.csv')\n",
    "test=test[['airline_sentiment','text']]\n",
    "test['Cleaned-Text']= [tweet_cleaner(x) for x in test['text']]\n",
    "#test['Cleaned-Text']=map(lambda x:tweet_cleaner(x),test['text'])\n",
    "test['Clean-Text-StopWords-Removed']= [RemoveStopWords(x) for x in test['Cleaned-Text']]\n",
    "#test['Clean-Text-StopWords-Removed']=map(lambda x:RemoveStopWords(x),test['Cleaned-Text'])\n",
    "test['Final-Wrangled-Text']= [RemoveExplicitlyMentionedWords(x,list_of_words_to_remove) for x in test['Clean-Text-StopWords-Removed']]\n",
    "#test['Final-Wrangled-Text']=map(lambda x:RemoveExplicitlyMentionedWords(x,list_of_words_to_remove),test['Clean-Text-StopWords-Removed'])\n",
    "x_test=vectorizer.transform(test['Final-Wrangled-Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['SentimentLabel']=l.transform(test['airline_sentiment'])\n",
    "y_test=test['SentimentLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raghu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "def GetOrignalSentiment(val):\n",
    "    if val==0:\n",
    "        return 'negative'\n",
    "    elif val==1:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "    \n",
    "Result=test[['text','airline_sentiment']]\n",
    "Result['Predicted_sentiment']= [GetOrignalSentiment(x) for x in y_pred ]\n",
    "#Result['Predicted_sentiment']=map(lambda x:GetOrignalSentiment(x),y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>Predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AmericanAir why did you drop my call. Why don...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USAirways thanks for the seat that doesn't re...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@AmericanAir wasn't just a delay. Your counter...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment  \\\n",
       "0  @AmericanAir why did you drop my call. Why don...          negative   \n",
       "1  @USAirways thanks for the seat that doesn't re...          negative   \n",
       "2  @AmericanAir wasn't just a delay. Your counter...          negative   \n",
       "\n",
       "  Predicted_sentiment  \n",
       "0            negative  \n",
       "1            negative  \n",
       "2            negative  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      " [[2397   78   33]\n",
      " [ 456  333   62]\n",
      " [ 225   51  365]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Confusion Matrix:\\n\\n\",metrics.confusion_matrix(Result['airline_sentiment'],Result['Predicted_sentiment'],labels=['negative','neutral','positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual negative Predicted negative: 2397\n",
      "Actual negative Predicted neutral: 78\n",
      "Actual negative Predicted positive: 33\n",
      "Actual neutral Predicted negative: 456\n",
      "Actual neutral Predicted neutral: 333\n",
      "Actual neutral Predicted positive: 62\n",
      "Actual positive Predicted negative: 225\n",
      "Actual positive Predicted neutral: 51\n",
      "Actual positive Predicted positive: 365\n"
     ]
    }
   ],
   "source": [
    "for i,x in Result.groupby(['airline_sentiment','Predicted_sentiment']):\n",
    "    print (\"Actual \"+ i[0]+ \" Predicted \"+i[1]+ \":\", len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 77.35 %\n"
     ]
    }
   ],
   "source": [
    "#Accuracy :\n",
    "ActualNegativePrdictedNegative=2396\n",
    "ActualNeutralPrdictedNeutral=333\n",
    "ActualPositivePrdictedPositive=365\n",
    "TotalCorrect=ActualNegativePrdictedNegative+ActualNeutralPrdictedNeutral+ActualPositivePrdictedPositive\n",
    "print (\"Accuracy=\",TotalCorrect*100.0/len(test) ,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
